<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Filter</title>
    <script src="https://cdn.jsdelivr.net/tracking.js/1.1.3/tracking-min.js"></script>
</head>
<body>
    <h1>Face Filter</h1>
    <video id="video" width="640" height="480" autoplay></video>
    <canvas id="canvas" width="640" height="480"></canvas>

    <script>
        // Initialize video and canvas
        var video = document.getElementById('video');
        var canvas = document.getElementById('canvas');
        var context = canvas.getContext('2d');
        var filterImage = new Image();
        filterImage.src = 'Cow.png'; // Replace with the path to your filter image

        // Load the tracking.js library and start face tracking
        tracking.track('#video', new tracking.FaceTracker());

        tracking.FramesPerSecond = 30; // Adjust frame rate as needed

        tracking.on('track', function (event) {
            context.clearRect(0, 0, canvas.width, canvas.height);
            
            event.data.forEach(function (rect) {
                context.drawImage(video, 0, 0, canvas.width, canvas.height);
                var scaleFactorX = rect.width / filterImage.width;
                var scaleFactorY = rect.height / filterImage.height;
                var x = rect.x;
                var y = rect.y - rect.height * 0.25; // Adjust the filter's vertical position
                
                // Draw the filter over the detected face
                context.drawImage(filterImage, x, y, rect.width, rect.height);
            });
        });

        // Access the user's camera
        navigator.mediaDevices.getUserMedia({ video: true })
            .then(function (stream) {
                video.srcObject = stream;
            })
            .catch(function (err) {
                console.error('Error accessing the camera: ' + err);
            });
    </script>
</body>
</html>
